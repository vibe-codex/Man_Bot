#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ—Ö–Ω–∏–∫ –∏–∑ Markdown —Ñ–∞–π–ª–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É PostgreSQL.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python load_knowledge.py --source ../KIMI_OUTPUT --provider google

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
    - –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π PostgreSQL —Å pgvector
    - –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ .env —Ñ–∞–π–ª–µ
    - –ö–ª—é—á API (Google/OpenAI/DeepSeek)
"""

import os
import sys
import re
import json
import argparse
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

import yaml
import asyncpg
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


@dataclass
class KnowledgeUnit:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –µ–¥–∏–Ω–∏—Ü—ã –∑–Ω–∞–Ω–∏—è"""
    ku_id: str
    title: str
    content: str
    yaml_data: Dict[str, Any]
    level: str
    user_level_fit: List[str]
    stage: List[str]
    channel: List[str]
    goal: List[str]
    style: List[str]
    riskiness: int
    embedding: Optional[List[float]] = None


class EmbeddingGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã"""
    
    def __init__(self, provider: str = "google"):
        self.provider = provider
        self.dimension = int(os.getenv("EMBED_DIMENSION", "768"))
        
        if provider == "google":
            self._init_google()
        elif provider == "openai":
            self._init_openai()
        elif provider == "deepseek":
            self._init_deepseek()
        else:
            raise ValueError(f"Unknown provider: {provider}")
    
    def _init_google(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Generative AI"""
        import google.generativeai as genai
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment")
        genai.configure(api_key=api_key)
        self.model = os.getenv("EMBED_MODEL", "models/embedding-001")
        self.client = genai
    
    def _init_openai(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI"""
        import openai
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found in environment")
        openai.api_key = api_key
        self.model = os.getenv("EMBED_MODEL", "text-embedding-3-small")
        self.client = openai
    
    def _init_deepseek(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DeepSeek"""
        # DeepSeek –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API
        import openai
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            raise ValueError("DEEPSEEK_API_KEY not found in environment")
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
        self.model = os.getenv("EMBED_MODEL", "deepseek-embedding")
    
    async def generate(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            if self.provider == "google":
                result = self.client.embed_content(
                    model=self.model,
                    content=text,
                    task_type="retrieval_document"
                )
                return result['embedding']
            
            elif self.provider in ["openai", "deepseek"]:
                response = self.client.embeddings.create(
                    model=self.model,
                    input=text
                )
                return response.data[0].embedding
                
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –∫–∞–∫ fallback
            return [0.0] * self.dimension


class MarkdownParser:
    """–ü–∞—Ä—Å–µ—Ä Markdown —Ñ–∞–π–ª–æ–≤ —Å YAML frontmatter"""
    
    @staticmethod
    def parse_file(filepath: Path) -> Optional[KnowledgeUnit]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω .md —Ñ–∞–π–ª"""
        try:
            content = filepath.read_text(encoding='utf-8')
            
            # –†–∞–∑–¥–µ–ª—è–µ–º frontmatter –∏ –∫–æ–Ω—Ç–µ–Ω—Ç
            if content.startswith('---'):
                parts = content.split('---', 2)
                if len(parts) >= 3:
                    yaml_content = parts[1].strip()
                    markdown_content = parts[2].strip()
                else:
                    return None
            else:
                return None
            
            # –ü–∞—Ä—Å–∏–º YAML
            try:
                yaml_data = yaml.safe_load(yaml_content)
            except yaml.YAMLError as e:
                print(f"‚ö†Ô∏è  YAML –æ—à–∏–±–∫–∞ –≤ {filepath.name}: {e}")
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª—è
            ku_id = yaml_data.get('id', filepath.stem)
            title = yaml_data.get('title', ku_id)
            level = yaml_data.get('Level', '–±–∞–∑–∞')
            user_level_fit = yaml_data.get('UserLevelFit', ['–Ω–æ–≤–∏—á–æ–∫'])
            stage = yaml_data.get('Stage', [])
            channel = yaml_data.get('Channel', [])
            goal = yaml_data.get('Goal', [])
            style = yaml_data.get('Style', [])
            riskiness = yaml_data.get('Riskiness', 1)
            
            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç YAML –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            clean_content = markdown_content
            # –£–¥–∞–ª—è–µ–º markdown-—Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è –ª—É—á—à–µ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            clean_content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', clean_content)  # —Å—Å—ã–ª–∫–∏
            clean_content = re.sub(r'[#*_`]', '', clean_content)  # markdown —Å–∏–º–≤–æ–ª—ã
            
            return KnowledgeUnit(
                ku_id=ku_id,
                title=title,
                content=markdown_content,
                yaml_data=yaml_data,
                level=level,
                user_level_fit=user_level_fit if isinstance(user_level_fit, list) else [user_level_fit],
                stage=stage if isinstance(stage, list) else [stage],
                channel=channel if isinstance(channel, list) else [channel],
                goal=goal if isinstance(goal, list) else [goal],
                style=style if isinstance(style, list) else [style],
                riskiness=riskiness
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {filepath}: {e}")
            return None


class DatabaseLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –≤ PostgreSQL"""
    
    def __init__(self, dsn: str):
        self.dsn = dsn
        self.conn = None
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ"""
        self.conn = await asyncpg.connect(self.dsn)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ PostgreSQL")
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.conn:
            await self.conn.close()
    
    async def insert_knowledge_unit(self, ku: KnowledgeUnit) -> bool:
        """–í—Å—Ç–∞–≤–∫–∞ –æ–¥–Ω–æ–π –µ–¥–∏–Ω–∏—Ü—ã –∑–Ω–∞–Ω–∏—è"""
        try:
            await self.conn.execute(
                """
                INSERT INTO knowledge_units 
                (ku_id, title, content, yaml, level, user_level_fit, stage, channel, goal, style, riskiness, embedding)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::vector)
                ON CONFLICT (ku_id) DO UPDATE SET
                    title = EXCLUDED.title,
                    content = EXCLUDED.content,
                    yaml = EXCLUDED.yaml,
                    level = EXCLUDED.level,
                    user_level_fit = EXCLUDED.user_level_fit,
                    stage = EXCLUDED.stage,
                    channel = EXCLUDED.channel,
                    goal = EXCLUDED.goal,
                    style = EXCLUDED.style,
                    riskiness = EXCLUDED.riskiness,
                    embedding = EXCLUDED.embedding,
                    updated_at = NOW()
                """,
                ku.ku_id,
                ku.title,
                ku.content,
                json.dumps(ku.yaml_data, ensure_ascii=False),
                ku.level,
                ku.user_level_fit,
                ku.stage,
                ku.channel,
                ku.goal,
                ku.style,
                ku.riskiness,
                ku.embedding
            )
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ {ku.ku_id}: {e}")
            return False
    
    async def get_stats(self) -> Dict[str, int]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã"""
        count = await self.conn.fetchval("SELECT COUNT(*) FROM knowledge_units")
        return {"total_units": count}


async def main():
    parser = argparse.ArgumentParser(description='–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Ö–Ω–∏–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É')
    parser.add_argument('--source', '-s', default='../KIMI_OUTPUT',
                       help='–ü–∞–ø–∫–∞ —Å .md —Ñ–∞–π–ª–∞–º–∏ (default: ../KIMI_OUTPUT)')
    parser.add_argument('--provider', '-p', default='google',
                       choices=['google', 'openai', 'deepseek'],
                       help='–ü—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (default: google)')
    parser.add_argument('--dsn', '-d', default=os.getenv('DB_DSN'),
                       help='PostgreSQL connection string')
    
    args = parser.parse_args()
    
    if not args.dsn:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–∫–∞–∑–∞–Ω DSN –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --dsn –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è DB_DSN")
        sys.exit(1)
    
    source_path = Path(args.source)
    if not source_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ {source_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        sys.exit(1)
    
    print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Ö–Ω–∏–∫ –∏–∑ {source_path}")
    print(f"üîß –ü—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {args.provider}")
    print()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    print("üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
    db = DatabaseLoader(args.dsn)
    await db.connect()
    
    print(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è {args.provider}...")
    try:
        embedder = EmbeddingGenerator(args.provider)
    except ValueError as e:
        print(f"‚ùå {e}")
        sys.exit(1)
    
    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    md_files = list(source_path.glob("*.md"))
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(md_files)}")
    print()
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –∏ –∑–∞–≥—Ä—É–∑–∫–∞
    successful = 0
    failed = 0
    
    for i, filepath in enumerate(md_files, 1):
        print(f"[{i}/{len(md_files)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ {filepath.name}...", end=" ")
        
        # –ü–∞—Ä—Å–∏–º
        ku = MarkdownParser.parse_file(filepath)
        if not ku:
            print("‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è")
            failed += 1
            continue
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        text_for_embedding = f"{ku.title}\n{ku.content[:1000]}"  # –ë–µ—Ä—ë–º –Ω–∞—á–∞–ª–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        ku.embedding = await embedder.generate(text_for_embedding)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –±–∞–∑—É
        if await db.insert_knowledge_unit(ku):
            print(f"‚úÖ {ku.ku_id}")
            successful += 1
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏")
            failed += 1
    
    # –ò—Ç–æ–≥–∏
    print()
    print("=" * 50)
    print("üìä –ò–¢–û–ì–ò –ó–ê–ì–†–£–ó–ö–ò:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
    print(f"   ‚ùå –û—à–∏–±–æ–∫: {failed}")
    
    stats = await db.get_stats()
    print(f"   üì¶ –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {stats['total_units']} —Ç–µ—Ö–Ω–∏–∫")
    print("=" * 50)
    
    await db.close()
    print()
    print("üéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –±–æ—Ç–∞.")


if __name__ == "__main__":
    asyncio.run(main())